{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the Content\n",
    "- https://docs.python-guide.org/scenarios/scrape/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "import json\n",
    "from lxml import html\n",
    "import unicodecsv as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data \n",
    "url = \"https://www.zillow.com/homes/m5e_rb/\"\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'}) \n",
    "webpage = urlopen(req).read()\n",
    "webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(webpage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `html.fromstring()` \n",
    "- implicitly expects bytes as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html.fromstring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = html.fromstring(\"<p>Hello, World!</p>\")\n",
    "type(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = html.fromstring(webpage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `parser` now contains the whole HTML file in a nice tree structure which we can go over two different ways: \n",
    "- XPath \n",
    "- CSSSelect\n",
    "\n",
    "### `XPath`\n",
    "`XPath` is a way of locating information in structured documents such as HTML or XML documents. \n",
    "- XPath stands for XML Path Language\n",
    "- XPath uses \"path like\" syntax to identify and navigate nodes in an XML document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('http://econpy.pythonanywhere.com/ex/001.html')\n",
    "tree = html.fromstring(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[example](http://econpy.pythonanywhere.com/ex/001.html)\n",
    "After a quick analysis, we see that in our page the data is contained in two elements – one is a div with title ‘buyer-name’ and the other is a span with class ‘item-price’:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buyers = tree.xpath('//div[@title=\"item-price\"]/text()')\n",
    "buyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to parsing zillow:\n",
    "search_results = parser.xpath(\"//div[@id='search-results']//article\")\n",
    "raw_json_data = parser.xpath('//script[@data-zrr-shared-data-key=\"mobileSearchPageStore\"]//text()')\n",
    "\n",
    "# still lots of garbages before actual listing part:\n",
    "raw_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # clean up text string\n",
    "    if text:\n",
    "        return ' '.join(' '.join(text).split())\n",
    "    return None\n",
    "\n",
    "cleaned_data = clean(raw_json_data).replace('<!--', \"\").replace(\"-->\", \"\")\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(cleaned_data) # parse cleaned_data\n",
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean list of dictionary of all the sales data \n",
    "search_results = json_data.get('cat1').get('searchResults').get('listResults', [])\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the needed columns\n",
    "all_data = []\n",
    "for properties in search_results:\n",
    "    title = properties.get('statusText')\n",
    "    property_url = properties.get('detailUrl')\n",
    "    \n",
    "    data = {'title': title, 'url': property_url}\n",
    "    all_data.append(data)\n",
    "\n",
    "all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_project",
   "language": "python",
   "name": "data_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import unicodecsv as csv\n",
    "import json\n",
    "import requests\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # clean up text string\n",
    "    if text:\n",
    "        return ' '.join(' '.join(text).split())\n",
    "    return None\n",
    "\n",
    "def get_headers():\n",
    "    # Creating headers.\n",
    "    headers = {'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "               'accept-encoding': 'gzip, deflate, sdch, br',\n",
    "               'accept-language': 'en-GB,en;q=0.8,en-US;q=0.6,ml;q=0.4',\n",
    "               'cache-control': 'max-age=0',\n",
    "               'upgrade-insecure-requests': '1',\n",
    "               'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36'}\n",
    "    return headers\n",
    "\n",
    "def create_url(zipcode, filter):\n",
    "    # Creating Zillow URL based on the filter.\n",
    "    url = \"https://www.zillow.com/homes/for_sale/{0}_rb/?fromHomePage=true&shouldFireSellPageImplicitClaimGA=false&fromHomePageTab=buy\".format(zipcode)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_json(raw_json_data):\n",
    "    # getting data from json (type 2 of their A/B testing page)\n",
    "\n",
    "    cleaned_data = clean(raw_json_data).replace('<!--', \"\").replace(\"-->\", \"\")\n",
    "    properties_list = []\n",
    "\n",
    "    try:\n",
    "        json_data = json.loads(cleaned_data)\n",
    "        search_results = json_data.get('cat1').get('searchResults').get('listResults', [])\n",
    "\n",
    "        # find all the attributes from webpage source\n",
    "        for properties in search_results:\n",
    "            property_info = properties.get('hdpData', {}).get('homeInfo')\n",
    "            address = property_info.get('streetAddress')\n",
    "            city = property_info.get('city')\n",
    "            state = property_info.get('state')\n",
    "            postal_code = property_info.get('zipcode')\n",
    "            lat = property_info.get('latitude')\n",
    "            lon = property_info.get('longitude')\n",
    "            days = property_info.get('daysOnZillow')\n",
    "            price = properties.get('price')\n",
    "            bedrooms = properties.get('beds')\n",
    "            bathrooms = properties.get('baths')\n",
    "            area = properties.get('area')\n",
    "            info = f'{bedrooms} bds, {bathrooms} ba ,{area} sqft'\n",
    "            broker = properties.get('brokerName')\n",
    "            property_url = properties.get('detailUrl')\n",
    "            title = properties.get('statusText')\n",
    "\n",
    "            data = {'address': address,\n",
    "                    'city': city,\n",
    "                    'state': state,\n",
    "                    'postal_code': postal_code,\n",
    "                    'lat': lat,\n",
    "                    'lon': lon,\n",
    "                    'days': days,\n",
    "                    'price': price,\n",
    "                    'facts and features': info,\n",
    "                    'real estate provider': broker,\n",
    "                    'url': property_url,\n",
    "                    'title': title}\n",
    "\n",
    "            # list of all listings\n",
    "            properties_list.append(data)\n",
    "        return properties_list\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Invalid json\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(zipcode, filter=None):\n",
    "    url = create_url(zipcode, filter)\n",
    "    response = get_response(url)\n",
    "   \n",
    "    if not response:\n",
    "        print(\"Failed to fetch the page!\")\n",
    "        return None\n",
    "\n",
    "    # These two new lines are added\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "\n",
    "    #replace the parser to take input added above\n",
    "    parser = html.fromstring(webpage)\n",
    "    search_results = parser.xpath(\"//div[@id='search-results']//article\")\n",
    "\n",
    "    if not search_results:\n",
    "        print(\"parsing from json data\")\n",
    "        # identified as type 2 page\n",
    "        raw_json_data = parser.xpath('//script[@data-zrr-shared-data-key=\"mobileSearchPageStore\"]//text()')\n",
    "        return get_data_from_json(raw_json_data)\n",
    "\n",
    "    print(\"parsing from html page\")\n",
    "    properties_list = []\n",
    "    for properties in search_results:\n",
    "        raw_address = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='streetAddress']//text()\")\n",
    "        raw_city = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='addressLocality']//text()\")\n",
    "        raw_state = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='addressRegion']//text()\")\n",
    "        raw_postal_code = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='postalCode']//text()\")\n",
    "        raw_price = properties.xpath(\".//span[@class='zsg-photo-card-price']//text()\")\n",
    "        raw_info = properties.xpath(\".//span[@class='zsg-photo-card-info']//text()\")\n",
    "        raw_broker_name = properties.xpath(\".//span[@class='zsg-photo-card-broker-name']//text()\")\n",
    "        url = properties.xpath(\".//a[contains(@class,'overlay-link')]/@href\")\n",
    "        raw_title = properties.xpath(\".//h4//text()\")\n",
    "\n",
    "        address = clean(raw_address)\n",
    "        city = clean(raw_city)\n",
    "        state = clean(raw_state)\n",
    "        postal_code = clean(raw_postal_code)\n",
    "        price = clean(raw_price)\n",
    "        info = clean(raw_info).replace(u\"\\xb7\", ',')\n",
    "        broker = clean(raw_broker_name)\n",
    "        title = clean(raw_title)\n",
    "        property_url = \"https://www.zillow.com\" + url[0] if url else None\n",
    "        is_forsale = properties.xpath('.//span[@class=\"zsg-icon-for-sale\"]')\n",
    "\n",
    "        properties = {'address': address,\n",
    "                      'city': city,\n",
    "                      'state': state,\n",
    "                      'postal_code': postal_code,\n",
    "                      'price': price,\n",
    "                      'facts and features': info,\n",
    "                      'real estate provider': broker,\n",
    "                      'url': property_url,\n",
    "                      'title': title}\n",
    "        if is_forsale:\n",
    "            properties_list.append(properties)\n",
    "    return properties_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(url):\n",
    "    # Getting response from zillow.com.\n",
    "\n",
    "    for i in range(5):\n",
    "        response = requests.get(url, headers=get_headers())\n",
    "        print(\"status code received:\", response.status_code, url)\n",
    "        if response.status_code != 200:\n",
    "            # saving response to file for debugging purpose.\n",
    "            save_to_file(response)\n",
    "            continue\n",
    "        else:\n",
    "            save_to_file(response)\n",
    "            return response\n",
    "    return None\n",
    "\n",
    "def save_to_file(response):\n",
    "    # saving response to `response.html`\n",
    "\n",
    "    with open(\"mls_data/response.html\", 'w') as fp:\n",
    "        fp.write(response.text)\n",
    "        \n",
    "def write_data_to_csv(data):\n",
    "    # saving scraped data to csv.\n",
    "\n",
    "    # with open(\"mls_data/for_sale-%s.csv\" % (zipcode), 'wb') as csvfile:\n",
    "    with open(\"mls_data/all_properties.csv\", 'wb') as csvfile:\n",
    "        fieldnames = [\n",
    "            'title', \n",
    "            'address', \n",
    "            'city', \n",
    "            'state', \n",
    "            'postal_code', \n",
    "            'lat',\n",
    "            'lon',\n",
    "            'price', \n",
    "            'days',\n",
    "            'facts and features', \n",
    "            'real estate provider', \n",
    "            'url']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for M4V\n",
      "status code received: 200 https://www.zillow.com/homes/for_sale/M4V_rb/?fromHomePage=true&shouldFireSellPageImplicitClaimGA=false&fromHomePageTab=buy/lotSize_sort\n",
      "parsing from json data\n",
      "Number of listing:  19\n"
     ]
    }
   ],
   "source": [
    "# tut: toronto zipcodes: https://worldpostalcode.com/canada/ontario/toronto\n",
    "zipcode_lst = [\"M4V\", \"M4T\", \"M5R\", \"M5P\", \"M5N\", \"M4N\", \"M4P\", \"M4R\", \"M4S\", \"M3K\", \"M5W\", \"M7Y\", \"M8V\",\n",
    "               \"M5S\", \"M5B\", \"M5X\", \"M5V\", \"M4W\", \"M4X\", \"M4Y\", \"M5A\", \"M5C\", \"M5T\", \"M5E\", \"M5G\", \"M5H\", \"M5J\",  \n",
    "               \"M5K\", \"M5L\", \"M6G\", \"M4E\", \"M4M\", \"M4L\", \"M4K\", \"M4J\", \"M6H\", \"M6J\", \"M6K\", \"M6P\", \"M6R\", \"M6S\",]\n",
    "\n",
    "# append zipcodes \n",
    "final_list = []\n",
    "for zipcode in zipcode_lst:\n",
    "    print (\"Fetching data for %s\" % (zipcode))\n",
    "    scraped_data = parse(zipcode)\n",
    "    for data in scraped_data:\n",
    "        final_list.append(data)\n",
    "    print (\"Number of listing: \", len(scraped_data))    \n",
    "\n",
    "# export data\n",
    "write_data_to_csv(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_project",
   "language": "python",
   "name": "data_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
